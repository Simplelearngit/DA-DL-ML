{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPPyqfyiu547tQ09G0q1YlO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":131},"id":"FBJ_tNITO1DG","executionInfo":{"status":"error","timestamp":1683783742047,"user_tz":-330,"elapsed":903,"user":{"displayName":"26. Nilam Kolekar","userId":"02147768789417748747"}},"outputId":"cf14980d-a288-4415-ea24-93a8b4b501c6"},"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-642bb74ca356>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    from tensorflow.keras.models\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras.models\n","import Sequential\n","from tensorflow.keras.layersimport Conv2D, UpSampling2D, InputLayer, BatchNormalization\n","from tensorflow.keras.preprocessing.image\n","import ImageDataGenerator, array_to_img, img_to_array,load_img\n","import numpy as np\n","# Load the grayscale image\n","img_gray = load_img('bw_image.jpg', grayscale=True)\n","# Resize the image to the desired size\n","img_gray = img_gray.resize((256,256))\n","# Convert the image to a numpy array\n","img_gray = img_to_array(img_gray)\n","# Normalize the image\n","img_gray = img_gray / 255.0\n","# Add a new dimension to the array to make it compatible with the input shape of the model\n","img_gray = np.expand_dims(img_gray, axis=0)\n","# Load the pre-trained model\n","model = Sequential()\n","model.add(InputLayer(input_shape=(None, None, 1)))\n","model.add(Conv2D(64, (3,3), activation='relu', padding='same', strides=2))\n","model.add(Conv2D(128, (3,3), activation='relu', padding='same'))\n","model.add(Conv2D(128, (3,3), activation='relu', padding='same', strides=2))\n","model.add(Conv2D(256, (3,3), activation='relu', padding='same'))\n","model.add(Conv2D(256, (3,3), activation='relu', padding='same', strides=2))\n","model.add(Conv2D(512, (3,3), activation='relu', padding='same'))\n","model.add(Conv2D(512, (3,3), activation='relu', padding='same'))\n","model.add(Conv2D(256, (3,3), activation='relu', padding='same'))\n","model.add(UpSampling2D((2,2)))\n","model.add(Conv2D(128, (3,3), activation='relu', padding='same'))\n","model.add(UpSampling2D((2,2)))\n","model.add(Conv2D(64, (3,3), activation='relu', padding='same'))\n","model.add(Conv2D(32, (3,3), activation='relu', padding='same'))\n","model.add(Conv2D(2, (3, 3), activation='tanh', padding='same'))\n","model.add(UpSampling2D((2, 2)))\n","model.compile(optimizer='adam', loss='mse')\n","# Load the pre-trained weights\n","model.load_weights('colorization_weights.h5')\n","# Colorize the grayscale image\n","img_colorized = model.predict(img_gray)\n","# Save the colorized image\n","img_colorized = img_colorized * 128 + 128\n","img_colorized = np.clip(img_colorized, 0, 255).astype('uint8')\n","img_colorized = array_to_img(img_colorized[0])\n","img_colorized.save('colorized_image.jpg')"]}]}